{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing\n",
    " - ex 3\n",
    "   - pdf of pareto\n",
    "   - pareto with support [beta, inf[\n",
    "    - pareto using composition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of lcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear congruential generator\n",
    "def lcg(x_0: int, a: int, c: int, M: int):\n",
    "    \"\"\"\n",
    "    x_0: seed\n",
    "    a: multiplier\n",
    "    c: increment\n",
    "    M: modulus and number of possible samples\n",
    "    \"\"\"\n",
    "\n",
    "    if math.gcd(a, M) != 1:\n",
    "        raise ValueError('a and M must be coprime')\n",
    "    assert all(isinstance(i, int) for i in [x_0, a, c, M]), 'All inputs must be integers'\n",
    "    \n",
    "    x = x_0\n",
    "    U = np.empty(M)\n",
    "    for i in range(M):\n",
    "        x = (a * x + c) % M\n",
    "        U[i] = x / M\n",
    "    return U\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of testing of random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_tests(u: np.ndarray, *, k: int=10, verbose: bool=True) -> tuple[float, ...]:\n",
    "    \"\"\"\n",
    "    k: number of bins for certain tests\n",
    "    \"\"\"\n",
    "    n = len(u)\n",
    "\n",
    "    # histrogram, ECDF, and scatter plot\n",
    "    if verbose:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        ax[0].hist(u, bins=k, density=True)\n",
    "        ax[0].set_title('Histogram')\n",
    "        ax[1].plot((0, 1), (0, 1), 'k--')\n",
    "        ax[1].ecdf(u)\n",
    "        ax[1].set_title('ECDF')\n",
    "        ax[2].plot(u, '.', markersize=1)\n",
    "        ax[2].set_title('Scatter plot')\n",
    "\n",
    "\n",
    "    # chi-squared test\n",
    "    expected = np.full(k, n / k)\n",
    "    observed, _ = np.histogram(u, bins=k)\n",
    "    chisq_stat = np.sum((observed - expected) ** 2 / expected)\n",
    "    chisq_p_value = 1 - stats.chi2.cdf(chisq_stat, k-1)\n",
    "    if verbose: print(f'Chi-squared: stat={chisq_stat:.2f}, p-value={chisq_p_value:.2f}')\n",
    "\n",
    "\n",
    "    # Kolmogorov-Smirnov test\n",
    "    u_sorted = np.sort(u)\n",
    "    cdf = np.arange(1, n + 1) / n\n",
    "    D_plus = np.max(cdf - u_sorted)\n",
    "    D_minus = np.max(u_sorted - (cdf - 1/n))\n",
    "    D_stat = max(D_plus, D_minus)\n",
    "    D_p_value = stats.kstwobign.sf(D_stat * np.sqrt(n))\n",
    "    if verbose: print(f'Kolmogorov-Smirnov: stat={D_stat:.2f}, p-value={D_p_value:.2f}')\n",
    "\n",
    "\n",
    "    # Wald-Wolfowitz runs test\n",
    "    median = np.median(u)\n",
    "    above_median = np.sum(u > median)\n",
    "    below_median = np.sum(u < median)\n",
    "\n",
    "    runs = u[u != median] > median\n",
    "    num_runs = np.sum(runs[1:] != runs[:-1]) + 1\n",
    "\n",
    "    mu = 2 * above_median * below_median / (above_median + below_median) + 1\n",
    "    sig_sq = 2 * above_median * below_median * (2 * above_median * below_median - above_median - below_median) / \\\n",
    "        ((above_median + below_median) ** 2 * (above_median + below_median - 1))\n",
    "\n",
    "    r1_stat = abs((num_runs - mu) / np.sqrt(sig_sq))\n",
    "    r1_p_value = 2 * (1 - stats.norm.cdf(r1_stat))\n",
    "    if verbose: print(f'Wald-Wolfowitz runs: stat={r1_stat:.2f}, p-value={r1_p_value:.2f}')\n",
    "\n",
    "\n",
    "    # Knuth up-down test\n",
    "    assert n >= 4000, 'must be at least 4000 random numbers to perform Knuth up-down test'\n",
    "\n",
    "    def count_runs_knuth(u: np.ndarray) -> tuple[float, float]:\n",
    "        runs_stops = np.where(u[1:] < u[:-1])[0] + 1\n",
    "        runs_lengths = np.diff(np.concatenate(([0], runs_stops, [len(u)])))\n",
    "        length, counts = np.unique(runs_lengths, return_counts=True)\n",
    "        run_length_counts = np.zeros(6)\n",
    "        for l, c in zip(length, counts):\n",
    "            if l >= 6:\n",
    "                run_length_counts[-1] += c\n",
    "            else:\n",
    "                run_length_counts[l-1] = c\n",
    "\n",
    "        R = run_length_counts[:, None]\n",
    "\n",
    "        A = np.array(\n",
    "            [[ 4529.4,  9044.9, 13568,  18091,  22615,  27892],\n",
    "             [ 9044.9, 18097.0, 27139,  36187,  45234,  55789],\n",
    "             [13568.0, 27139.0, 40721,  54281,  67852,  83685],\n",
    "             [18091.0, 36187.0, 54281,  72414,  90470, 111580],\n",
    "             [22615.0, 45234.0, 67852,  90470, 113262, 139476],\n",
    "             [27892.0, 55789.0, 83685, 111580, 139476, 172860]])\n",
    "        B = np.array([[1/6, 5/24, 11/120, 19/720, 29/5040, 1/840]]).T\n",
    "\n",
    "        r2_stat = ((R - n * B).T @ A @ (R - n * B) / (n - 6)).item()\n",
    "        r2_p_value = 1 - stats.chi2.cdf(r2_stat, 6)\n",
    "\n",
    "        return r2_stat, r2_p_value\n",
    "\n",
    "    r2_stat_up, r2_p_value_up = count_runs_knuth(u)\n",
    "    r2_stat_down, r2_p_value_down = count_runs_knuth(1 - u)\n",
    "    if verbose:\n",
    "        print('Up')\n",
    "        print(f'Knuth up-down: stat={r2_stat_up:.2f}, p-value={r2_p_value_up:.2f}')\n",
    "        print('Down')\n",
    "        print(f'Knuth up-down: stat={r2_stat_down:.2f}, p-value={r2_p_value_down:.2f}')\n",
    "\n",
    "\n",
    "    # Run test III\n",
    "    up_down = np.concatenate(([u[0]], u[1:][u[1:] != u[:-1]])) # remove consecutive duplicates\n",
    "    up_down = up_down[1:] > up_down[:-1] # True if up, False if down\n",
    "\n",
    "    X = np.sum(up_down[1:] != up_down[:-1]) + 1\n",
    "    r3_stat = (X - (2 * len(up_down) - 1) / 3) / np.sqrt((16 * len(up_down) - 29) / 90)\n",
    "    r3_stat = abs(r3_stat)\n",
    "    r3_p_value = 2 * (1 - stats.norm.cdf(r3_stat))\n",
    "    if verbose: print(f'Run test III: stat={r3_stat:.2f}, p-value={r3_p_value:.2f}')\n",
    "\n",
    "\n",
    "    # correlation test\n",
    "    h = 1\n",
    "    c_h = np.sum(u[h:] * u[:-h]) / (n - h)\n",
    "    corr_stat = np.abs((c_h - 0.25) / np.sqrt(7 / (144 * n)))\n",
    "    corr_p_value = 2 * (1 - stats.norm.cdf(corr_stat))\n",
    "    if verbose: print(f'Correlation: stat={corr_stat:.2f}, p-value={corr_p_value:.2f}')\n",
    "\n",
    "    return chisq_p_value, D_p_value, r1_p_value, r2_p_value_up, r2_p_value_down, r3_p_value, corr_p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing lcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 127\n",
    "n = 10_000\n",
    "a = 1664521\n",
    "c = 1013904223\n",
    "u = lcg(0, a=a, c=c, M=n)\n",
    "\n",
    "\n",
    "_ = do_tests(u, verbose=True)\n",
    "plt.suptitle('Good parameters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 127\n",
    "n = 10_001\n",
    "a = 5\n",
    "c = 6\n",
    "u = lcg(0, a=a, c=c, M=n)\n",
    "\n",
    "\n",
    "_ = do_tests(u, verbose=True)\n",
    "plt.suptitle('Bad parameters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_random_tests = 10_000\n",
    "n = 10_000\n",
    "\n",
    "from random import random\n",
    "\n",
    "results = np.empty((num_random_tests, 7))\n",
    "for i in tqdm.trange(num_random_tests, leave=False):\n",
    "    u = np.array([random()for i in range(n)])\n",
    "    results[i] = do_tests(u, verbose=False)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for i, (ax, title) in enumerate(zip(\n",
    "    ax.flatten(),\n",
    "    ['Chi-squared', 'Kolmogorov-Smirnov', 'Wald-Wolfowitz runs', 'Knuth up', 'Knuth down', 'Run test III', 'Correlation']\n",
    ")):\n",
    "    ax.ecdf(results[:, i])\n",
    "    ax.set_title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "p = 0.5\n",
    "u = np.random.rand(n)\n",
    "\n",
    "geometric = np.floor(np.log(u) / np.log(1 - p)) + 1\n",
    "cov, counts = np.unique(geometric, return_counts=True)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(cov, counts / n)\n",
    "plt.yscale('log')\n",
    "plt.title('Geometric distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crude_sampling(p: np.array, n: int) -> np.ndarray:\n",
    "    u = np.random.rand(n)\n",
    "    return (u < np.cumsum(p)[:, None]).argmax(axis=0) + 1\n",
    "100\n",
    "\n",
    "def rejection_sampling(p: np.ndarray, n: int) -> np.ndarray:\n",
    "    assert np.isclose(np.sum(p), 1), 'p must sum to 1'\n",
    "\n",
    "    k = len(p)\n",
    "    c = np.max(p)\n",
    "    p_over_c = p / c\n",
    "    samples = np.empty(n, dtype=int)\n",
    "    for i in range(n):\n",
    "        while True:\n",
    "            u1, u2 = np.random.rand(2)\n",
    "            I = np.floor(k * u1).astype(int) + 1\n",
    "            if u2 <= p_over_c[I-1]:\n",
    "                samples[i] = I\n",
    "                break\n",
    "    return samples\n",
    "\n",
    "\n",
    "def alias_sampling(p: np.ndarray, num_samples: int) -> np.ndarray:\n",
    "\n",
    "    # preprocessing\n",
    "    n = len(p)\n",
    "    scaled = n * p\n",
    "\n",
    "    small_queue: list[int] = np.where(scaled < 1)[0].tolist()\n",
    "    large_queue: list[int] = np.where(scaled >= 1)[0].tolist()\n",
    "\n",
    "    prob = np.zeros(n)\n",
    "    alias = np.zeros(n, dtype=int)\n",
    "\n",
    "    while small_queue and large_queue:\n",
    "        l = small_queue.pop()\n",
    "        g = large_queue.pop()\n",
    "\n",
    "        prob[l] = scaled[l]\n",
    "        alias[l] = g\n",
    "\n",
    "        scaled[g] += scaled[l] - 1\n",
    "\n",
    "        (large_queue, small_queue)[bool(scaled[g] < 1)].append(g)\n",
    "\n",
    "    for i in small_queue + large_queue:\n",
    "        prob[i] = 1\n",
    "\n",
    "    # sampling\n",
    "    x = np.random.rand(num_samples)\n",
    "    i = np.floor(x * n).astype(int)\n",
    "    y = n * x - i\n",
    "\n",
    "    return np.where(y < prob[i], i, alias[i]) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "p = np.array([7, 5, 6, 3, 12, 15]) / 48\n",
    "\n",
    "dist_crude = crude_sampling(p, n)\n",
    "dist_rejection = rejection_sampling(p, n)\n",
    "dist_alias = alias_sampling(p, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "p_crude = np.bincount(dist_crude, minlength=7)[1:] / n\n",
    "p_rejection = np.bincount(dist_rejection, minlength=7)[1:] / n\n",
    "p_alias = np.bincount(dist_alias, minlength=7)[1:] / n\n",
    "\n",
    "ax[0, 0].bar(np.arange(1, 7), p)\n",
    "ax[0, 0].set_title('Expected distribution')\n",
    "ax[0, 1].bar(np.arange(1, 7), p_crude)\n",
    "ax[0, 1].set_title(f'Crude sampling, p-value={stats.chisquare(p, p_crude).pvalue:.2f}')\n",
    "ax[1, 0].bar(np.arange(1, 7), p_rejection)\n",
    "ax[1, 0].set_title(f'Rejection sampling, p-value={stats.chisquare(p, p_rejection).pvalue:.2f}')\n",
    "ax[1, 1].bar(np.arange(1, 7), p_alias)\n",
    "ax[1, 1].set_title(f'Alias sampling, p-value={stats.chisquare(p, p_alias).pvalue:.2f}')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_exp(n: int, _lambda: float) -> np.ndarray:\n",
    "    u = np.random.rand(n)\n",
    "    return -np.log(u) / _lambda\n",
    "\n",
    "\n",
    "def sample_pareto(n: int, k: float, beta: float) -> np.ndarray:\n",
    "    u = np.random.rand(n)\n",
    "    return beta * np.power(u, -1/k)\n",
    "\n",
    "\n",
    "def sample_gaussian(n: int, mu: float=0, sigma: float=1) -> np.ndarray:\n",
    "    u1 = np.random.rand(n)\n",
    "    u2 = np.random.rand(n)\n",
    "    return np.sqrt(-2 * np.log(u1)) * np.cos(2 * np.pi * u2) * sigma + mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "_lambda = 0.5\n",
    "mu = 0\n",
    "sigma = 1\n",
    "\n",
    "X_exp = sample_exp(n, _lambda)\n",
    "X_gaussian = sample_gaussian(n, mu, sigma)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "xs = np.linspace(0, max(X_exp), 1_000)\n",
    "ys = _lambda * np.exp(- _lambda * xs)\n",
    "ax[0].hist(X_exp, bins=50, density=True)\n",
    "ax[0].plot(xs, ys)\n",
    "ax[0].set_title(f'Exponential distribution, p-value={stats.kstest(X_exp, stats.expon(0, 1/_lambda).cdf).pvalue:.2f}')\n",
    "\n",
    "xs = np.linspace(X_gaussian.min(), X_gaussian.max(), 1_000)\n",
    "ys = np.exp(-((xs - mu) / sigma) ** 2 / 2) / (sigma * np.sqrt(2 * np.pi))\n",
    "ax[1].hist(X_gaussian, bins=50, density=True)\n",
    "ax[1].plot(xs, ys)\n",
    "ax[1].set_title(f'Gaussian distribution, p-value={stats.kstest(X_gaussian, stats.norm(mu, sigma).cdf).pvalue:.2f}')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "for k, ax in zip(\n",
    "    (2.05, 2.5, 3, 4),\n",
    "    axs\n",
    "):\n",
    "    X_pareto = sample_pareto(n, k, beta)\n",
    "    # ax.hist(X_pareto, bins=50, density=True)\n",
    "    ax.ecdf(X_pareto, label='Sampled')\n",
    "    ax.set_title(f'$beta$={beta}, k={k}')\n",
    "\n",
    "    max_val = np.max(X_pareto)\n",
    "    xs = np.linspace(beta, max_val, 10_000)\n",
    "    F_pareto = lambda x, k=k, beta=beta: 1 - np.power(beta / x, k)\n",
    "    ys = F_pareto(xs, k, beta)\n",
    "    ax.plot(xs, ys, label='Expected')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Pareto distribution, p-value={stats.kstest(X_pareto, F_pareto).pvalue:.2f}')\n",
    "\n",
    "    print(f'{k=}, {beta=}')\n",
    "    print('Expected:')\n",
    "    print(\n",
    "        f'mean={beta * k / (k - 1):.3},',\n",
    "        f'var={beta ** 2 * k / ((k - 1) ** 2 * (k - 2)):.3}'\n",
    "    )\n",
    "    print('Actual:')\n",
    "    print(\n",
    "        f'mean={np.mean(X_pareto):.3},',\n",
    "        f'var={np.var(X_pareto):.3}'\n",
    "    )\n",
    "    print()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "mu = 0\n",
    "sigma = 1\n",
    "num_tests = 100\n",
    "\n",
    "# estimater, 2.5% and 97.5%\n",
    "means = np.empty(num_tests)\n",
    "variances = np.empty(num_tests)\n",
    "\n",
    "for i in range(num_tests):\n",
    "    u = sample_gaussian(n, mu, sigma)\n",
    "    means[i] = np.mean(u)\n",
    "    variances[i] = np.square(u - means[i]).sum() / (n - 1)\n",
    "\n",
    "s = np.sqrt(variances)\n",
    "mu_lower = means + stats.t.ppf(0.025, df=n-1) * s / np.sqrt(n)\n",
    "mu_upper = means - stats.t.ppf(0.025, df=n-1) * s / np.sqrt(n)\n",
    "\n",
    "var_lower = (n - 1) * variances / stats.chi2.ppf(0.975, df=n-1)\n",
    "var_upper = (n - 1) * variances / stats.chi2.ppf(0.025, df=n-1)\n",
    "\n",
    "mean_coverage = np.mean((mu_lower < mu) & (mu_upper > mu))\n",
    "var_coverage = np.mean((var_lower < sigma ** 2) & (var_upper > sigma ** 2))\n",
    "\n",
    "print(f'Mean coverage: {mean_coverage:.2f}')\n",
    "print(f'Var coverage: {var_coverage:.2f}')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ys = np.arange(num_tests)\n",
    "ax[1].scatter(var_lower, ys, label='Lower')\n",
    "ax[1].scatter(var_upper, ys, label='Upper')\n",
    "ax[1].scatter(variances, ys, label='Estimate')\n",
    "ax[1].vlines(sigma ** 2, 0, num_tests, color='r', label='True')\n",
    "ax[1].set_title(f'Variance 95% CI, coverage={var_coverage:.2f}')\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[0].scatter(mu_lower, ys, label='Lower')\n",
    "ax[0].scatter(mu_upper, ys, label='Upper')\n",
    "ax[0].scatter(means, ys, label='Estimate')\n",
    "ax[0].vlines(mu, 0, num_tests, color='r', label='True')\n",
    "ax[0].set_title(f'Mean 95% CI, coverage={mean_coverage:.2f}')\n",
    "ax[0].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "t = (means - mu) / (np.sqrt(variances / n))\n",
    "mean_p_values = stats.t.cdf(t, df=n-1)\n",
    "\n",
    "q = (n - 1) * variances / sigma ** 2\n",
    "var_p_values = stats.chi2.cdf(q, df=n-1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].ecdf(mean_p_values)\n",
    "ax[0].set_title('Mean p-values')\n",
    "ax[1].ecdf(var_p_values)\n",
    "ax[1].set_title('Var p-values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.5\n",
    "n = 10_000\n",
    "\n",
    "samples = np.random.exponential(\n",
    "    1/np.random.exponential(1/mu, n))\n",
    "\n",
    "xs = np.linspace(samples.min(), samples.max(), 10_000)\n",
    "F_pareto = lambda x, mu=mu: 1 - 1 / (1 + x / mu)\n",
    "\n",
    "plt.plot(xs, F_pareto(xs), label='Expected')\n",
    "plt.ecdf(samples, label='Sampled')\n",
    "plt.legend()\n",
    "plt.title(f'Pareto distribution, p-value={stats.kstest(samples, F_pareto).pvalue:.2f}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import math\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 10\n",
    "\n",
    "num_service_units = 10\n",
    "mean_service_time = 8.\n",
    "num_customers = 10_000\n",
    "\n",
    "# exp and erlang\n",
    "mean_customer_arrival_time = 1.\n",
    "\n",
    "# hyp_exp\n",
    "p = np.array([0.8, 0.2])\n",
    "_lambdas = np.array([0.8333, 5.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_process: Literal['exp', 'erlang', 'hyp_exp']\n",
    "service_process: Literal['exp', 'constant', 'pareto1.05', 'pareto2.05']\n",
    "\n",
    "results_dict = dict(params=dict(\n",
    "    num_experiments=num_experiments,\n",
    "    num_service_units=num_service_units,\n",
    "    mean_service_time=mean_service_time,\n",
    "    num_customers=num_customers,\n",
    "    mean_customer_arrival_time=mean_customer_arrival_time,\n",
    "    p=p,\n",
    "    _lambdas=_lambdas\n",
    "))\n",
    "\n",
    "# for arrival_process in tqdm.tqdm(['exp', 'erlang', 'hyp_exp'], 'arrival_process', leave=False):\n",
    "for arrival_process in tqdm.tqdm(['exp'], 'arrival_process', leave=False):\n",
    "    clear_output(wait=True)\n",
    "    results_dict[arrival_process] = dict()\n",
    "\n",
    "    for service_process in tqdm.tqdm(['exp', 'constant', 'pareto1.05', 'pareto2.05'], 'service_process', leave=False):\n",
    "\n",
    "        if service_process == 'exp':\n",
    "            get_service_time = lambda: stats.expon.rvs(scale=mean_service_time)\n",
    "        elif service_process == 'constant':\n",
    "            get_service_time = lambda: mean_service_time\n",
    "        elif service_process == 'pareto1.05':\n",
    "            get_service_time = lambda: stats.pareto.rvs(1.05)\n",
    "        elif service_process == 'pareto2.05':\n",
    "            get_service_time = lambda: stats.pareto.rvs(2.05)\n",
    "        else:\n",
    "            ValueError(service_process)\n",
    "\n",
    "        results = np.empty(num_experiments, dtype=int)\n",
    "        service_units = np.zeros(num_service_units)\n",
    "        for i in tqdm.trange(num_experiments, desc='experiments', leave=False):\n",
    "            \n",
    "            if arrival_process == 'exp':\n",
    "                time_between_customer_arrivals = stats.expon.rvs(\n",
    "                    scale=mean_customer_arrival_time,\n",
    "                    size=num_customers)\n",
    "            elif arrival_process == 'erlang':\n",
    "                time_between_customer_arrivals = stats.erlang.rvs(\n",
    "                    mean_customer_arrival_time,\n",
    "                    scale=mean_customer_arrival_time,\n",
    "                    size=num_customers)\n",
    "            elif arrival_process == 'hyp_exp':\n",
    "                scales = (1 / _lambdas)[np.random.choice(2, size=num_customers, p=p)]\n",
    "                time_between_customer_arrivals = np.random.exponential(scale=scales)\n",
    "            else:\n",
    "                ValueError(arrival_process)\n",
    "\n",
    "            unserved_customers = 0\n",
    "            for c in tqdm.tqdm(time_between_customer_arrivals, 'run', leave=False, disable=True):\n",
    "                service_units -= c\n",
    "                free_counters, = np.where(service_units <= 0)\n",
    "\n",
    "                if len(free_counters):\n",
    "                    service_units[free_counters[0]] = get_service_time()\n",
    "                else:\n",
    "                    unserved_customers += 1\n",
    "\n",
    "            results[i] = unserved_customers\n",
    "        \n",
    "        results_dict[arrival_process][service_process] = results\n",
    "\n",
    "np.save('results.npy', results_dict)\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = np.load('results.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = mean_service_time / mean_customer_arrival_time\n",
    "numerator = A ** num_service_units / math.factorial(num_service_units)\n",
    "denominator = np.sum([A ** i / math.factorial(i) for i in range(num_service_units)])\n",
    "p_erlang = numerator / denominator\n",
    "\n",
    "print(f'p_erlang={p_erlang:.3f}')\n",
    "print()\n",
    "\n",
    "for service_dist, num_unserviced in results_dict['exp'].items():\n",
    "    print(service_dist)\n",
    "    p_hat = num_unserviced.mean() / num_customers\n",
    "    n = num_customers * num_experiments\n",
    "    diff = 1.96 * np.sqrt(p_hat * (1 - p_hat) / n)\n",
    "    print(f'p_hat={p_hat:.3f}, 95% CI=({p_hat - diff:.3f}, {p_hat + diff:.3f})')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(n: int) -> float:\n",
    "    u = np.random.uniform(0, 1, n)\n",
    "    return np.exp(u).mean()\n",
    "\n",
    "\n",
    "def antithetic(n: int) -> float:\n",
    "    u = np.random.uniform(0, 1, n)\n",
    "    x = np.exp(u)\n",
    "    return (x + np.exp(1) / x).mean() / 2\n",
    "\n",
    "\n",
    "def control_variate(n: int) -> float:\n",
    "    u = np.random.uniform(0, 1, n)\n",
    "    x = np.exp(u)\n",
    "    cov, var = np.cov(x, u)[1]\n",
    "    c = -cov / var\n",
    "    z = x + c * (u - 0.5)\n",
    "    return z.mean()\n",
    "\n",
    "\n",
    "def stratified(n: int, n_strata: int=10) -> float:\n",
    "    strata = np.linspace(0, 1, n_strata, endpoint=False)[:, None]\n",
    "    u = np.random.uniform(0, 1 / n_strata, (n_strata, n))\n",
    "    return np.exp(strata + u).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "num_init_samples = 10_000\n",
    "num_tests = 10_000\n",
    "\n",
    "total_times = np.array([timeit.timeit(lambda: func(num_init_samples), number=num_tests)\n",
    "                        for func in (monte_carlo, antithetic, control_variate, stratified)])\n",
    "total_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = np.floor(total_times[0] / total_times * num_init_samples).astype(int)\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_times_adjusted = np.array([timeit.timeit(lambda: func(_n), number=num_tests)\n",
    "                        for func, _n in zip(\n",
    "                            (monte_carlo, antithetic, control_variate, stratified),\n",
    "                            num_samples)])\n",
    "total_times_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = [[func(_n) for _ in range(10_000)]\n",
    "              for func, _n in zip(\n",
    "                  (monte_carlo, antithetic, control_variate, stratified),\n",
    "                  num_samples)]\n",
    "estimates = np.array(estimates)\n",
    "np.var(estimates, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "mu = 0\n",
    "var = 1\n",
    "a = 4\n",
    "num_dec = 5\n",
    "n = 100_000\n",
    "\n",
    "# monte carlo\n",
    "u = np.random.uniform(0, 1, n)\n",
    "f = stats.norm.ppf(u, mu, var)\n",
    "prob_mc = np.mean(f > a)\n",
    "\n",
    "# importance sampling\n",
    "g = stats.norm(a, var).rvs(n)\n",
    "prob_is = np.mean((g > a) * stats.norm(mu, var).pdf(g) / stats.norm(a, var).pdf(g))\n",
    "\n",
    "print(f'Ground truth: {1 - stats.norm(mu, var).cdf(a):.{num_dec}}')\n",
    "print(f'monte carlo: {prob_mc:.{num_dec}}')\n",
    "print(f'importance sampling: {prob_is:.{num_dec}}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "num_repeats = 500\n",
    "lambdas = np.linspace(0.05, 6, 100)\n",
    "\n",
    "retults = np.empty((num_repeats, len(lambdas)))\n",
    "for i, _lambda in tqdm.tqdm(enumerate(lambdas), leave=False, total=len(lambdas)):\n",
    "    for ii in range(num_repeats):\n",
    "        g = stats.expon(0, 1/_lambda).rvs(n)\n",
    "        int_is = np.exp(g) * (g < 1) / stats.expon(0, 1/_lambda).pdf(g)\n",
    "        retults[ii, i] = int_is.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.var(retults, axis=0)\n",
    "plt.plot(lambdas, ys, label='IS variance')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('variance')\n",
    "plt.vlines(np.exp(1)/2, 0, ys.max(), label='Approximate minimum')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1.\n",
    "s = 8\n",
    "A = _lambda * s\n",
    "m = 10\n",
    "n = 1_000_000\n",
    "\n",
    "truncated_poisson = lambda i: A ** i / math.factorial(i)\n",
    "P = np.array([truncated_poisson(i) for i in range(m)])\n",
    "\n",
    "x = 7\n",
    "accepted = np.empty(n, dtype=bool)\n",
    "samples = np.empty(n, dtype=int)\n",
    "for i in tqdm.trange(n):\n",
    "    x_proposal = np.random.choice(m)\n",
    "    acc = np.random.rand() < truncated_poisson(x_proposal) / truncated_poisson(x)\n",
    "    if acc:\n",
    "        x = x_proposal\n",
    "    accepted[i] = acc\n",
    "    samples[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(np.cumsum(accepted) / np.arange(1, n + 1))\n",
    "ax[0].set_title('Acceptance rate')\n",
    "ax[1].plot(samples, range(n-1, -1, -1))\n",
    "ax[1].set_title('Samples')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(m)\n",
    "state, _counts = np.unique(samples, return_counts=True)\n",
    "counts[state] = _counts\n",
    "\n",
    "plt.title(f'Sample distribution comparison, p-value={stats.chisquare(counts, P/P.sum() * n).pvalue:.2}')\n",
    "plt.bar(np.arange(m)-0.25, counts / n, np.full(m, 0.5), edgecolor='black', label='MCMC')\n",
    "plt.bar(np.arange(m)+0.25, P/P.sum(), np.full(m, 0.5), edgecolor='black', label='Truncated Poisson')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = A2 = 4\n",
    "m = 10\n",
    "n = 1_000_000\n",
    "\n",
    "truncated_poisson = lambda i, j: A1 ** i / math.factorial(i) * A2 ** j / math.factorial(j)\n",
    "P = np.array([[truncated_poisson(i,j) for i in range(m)] for j in range(m)])\n",
    "\n",
    "x = np.array([l for l, *_ in np.where(P == P.max())], dtype=int)\n",
    "accepted = np.empty(n, dtype=bool)\n",
    "MH_samples = np.empty((n, 2), dtype=int)\n",
    "for i in tqdm.trange(n):\n",
    "    x_proposal = np.random.choice(m, size=2, replace=True)\n",
    "    u = np.random.rand()\n",
    "    acc = u < truncated_poisson(*x_proposal) / truncated_poisson(*x)\n",
    "    if acc:\n",
    "        x = x_proposal\n",
    "    accepted[i] = acc\n",
    "    MH_samples[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(np.cumsum(accepted) / np.arange(1, n + 1))\n",
    "ax[0].set_title('Acceptance rate')\n",
    "\n",
    "\n",
    "points = MH_samples[:, None, :]\n",
    "segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "lc = LineCollection(segments, cmap='viridis', norm=plt.Normalize(0, n), alpha=0.1)\n",
    "lc.set_array(np.arange(n))\n",
    "lc.set_linewidth(2)\n",
    "line = ax[1].add_collection(lc)\n",
    "fig.colorbar(line, ax=ax[1])\n",
    "\n",
    "ax[1].set_xlim(0, m-1)\n",
    "ax[1].set_ylim(0, m-1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = A2 = 4\n",
    "m = 10\n",
    "n = 1_000_000\n",
    "n_dims = 2\n",
    "\n",
    "truncated_poisson = lambda i, j: A1 ** i / math.factorial(i) * A2 ** j / math.factorial(j)\n",
    "P = np.array([[truncated_poisson(i,j) for i in range(m)] for j in range(m)])\n",
    "\n",
    "x = np.array([l for l, *_ in np.where(P == P.max())], dtype=int)\n",
    "accepted = np.empty((n, n_dims), dtype=bool)\n",
    "CMCMC_samples = np.empty((n, n_dims), dtype=int)\n",
    "for i in tqdm.trange(n):\n",
    "    for ii in range(n_dims):\n",
    "        x_proposal = x.copy()\n",
    "        x_proposal[ii] = np.random.choice(m)\n",
    "        u = np.random.rand()\n",
    "        acc = u < truncated_poisson(*x_proposal) / truncated_poisson(*x)\n",
    "        if acc:\n",
    "            x = x_proposal\n",
    "        \n",
    "        accepted[i, ii] = acc\n",
    "    \n",
    "    CMCMC_samples[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for title, samples in zip(\n",
    "    ('MH', 'CMCMC'),\n",
    "    (MH_samples, CMCMC_samples)\n",
    "):\n",
    "    counts = np.zeros((m, m), dtype=int)\n",
    "    for key, count in Counter(tuple(x) for x in samples).items():\n",
    "        counts[key] = count\n",
    "\n",
    "    print(title)\n",
    "    print(stats.chisquare(counts.flatten(), P.flatten() / P.sum() * n).pvalue)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.5\n",
    "\n",
    "xi, gamma = np.random.multivariate_normal(mean=[0, 0], cov=[[1, rho], [rho, 1]])\n",
    "theta, phi = np.exp((xi, gamma))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
